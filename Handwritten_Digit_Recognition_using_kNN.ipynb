{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten Digit Recognition using kNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "98c17213-ead9-401b-ab44-7ac757463452"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhCQhICpnDAc"
      },
      "source": [
        "### Downloading MNIST Train and Test Datasets  \n",
        " \n",
        "* **Proceed to further steps only after executing the cells in this section**.\n",
        "* The variables from these steps are used in some of the sample test cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af2b3cb8-8391-471c-9271-03ad0901be20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3041334-0645-46b0-c21e-5673f7784720"
      },
      "source": [
        "# Downloading the datasets using wget\n",
        "!wget https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/mnist_train.csv\n",
        "!wget https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/mnist_test.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-21 10:49:26--  https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/mnist_train.csv\n",
            "Resolving nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com (nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com)... 52.219.64.111\n",
            "Connecting to nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com (nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com)|52.219.64.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109575994 (104M) [text/csv]\n",
            "Saving to: ‘mnist_train.csv’\n",
            "\n",
            "mnist_train.csv     100%[===================>] 104.50M  11.8MB/s    in 11s     \n",
            "\n",
            "2021-07-21 10:49:37 (9.55 MB/s) - ‘mnist_train.csv’ saved [109575994/109575994]\n",
            "\n",
            "--2021-07-21 10:49:38--  https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/mnist_test.csv\n",
            "Resolving nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com (nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com)... 52.219.160.54\n",
            "Connecting to nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com (nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com)|52.219.160.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18289443 (17M) [text/csv]\n",
            "Saving to: ‘mnist_test.csv’\n",
            "\n",
            "mnist_test.csv      100%[===================>]  17.44M  5.19MB/s    in 3.4s    \n",
            "\n",
            "2021-07-21 10:49:42 (5.19 MB/s) - ‘mnist_test.csv’ saved [18289443/18289443]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "328c3961-828b-49c4-84de-9421c795ef93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ee7c9e-fe1a-44d6-f08c-52ed434a3676"
      },
      "source": [
        "# Checking the last few lines of the downloaded files\n",
        "!tail mnist_train.csv\n",
        "!tail mnist_test.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,107,229,255,254,26,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,157,242,253,253,165,227,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,130,244,253,184,54,10,1,7,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,179,253,181,67,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,208,181,99,4,0,0,0,0,4,27,120,200,118,0,0,0,0,0,0,0,0,0,0,0,0,0,0,234,253,73,0,0,0,0,12,73,137,253,253,253,79,0,0,0,0,0,0,0,0,0,0,0,0,0,123,251,151,20,16,61,141,223,226,238,253,253,237,64,5,0,0,0,0,0,0,0,0,0,0,0,0,0,99,249,253,253,253,252,191,150,74,22,242,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,91,144,53,41,40,0,0,21,202,253,100,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,212,253,95,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,243,253,101,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,170,237,135,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,188,253,113,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,115,251,149,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,86,229,218,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,117,240,189,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,116,229,173,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,88,243,216,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,226,248,103,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,226,142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,24,24,24,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,162,204,254,253,253,136,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,143,235,253,253,216,184,235,253,75,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,87,253,253,177,109,21,0,91,253,170,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,137,54,4,0,0,0,38,233,190,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,76,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,216,211,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,143,235,154,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,212,154,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,106,244,232,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,234,243,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,175,253,136,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,70,70,57,0,0,0,0,13,172,228,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,100,225,253,254,245,208,114,93,104,216,228,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,148,247,253,200,138,212,253,253,253,254,253,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,98,254,206,116,11,3,119,254,254,254,245,254,223,44,24,0,0,0,0,0,0,0,0,0,0,0,0,0,254,224,25,0,43,119,253,253,215,102,51,92,176,207,207,0,0,0,0,0,0,0,0,0,0,0,0,0,255,241,153,164,247,255,209,100,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,170,253,253,253,117,46,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,23,23,23,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,70,161,249,213,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,109,193,231,253,217,224,254,169,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,191,247,186,136,54,0,48,254,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,217,179,22,0,0,0,0,48,207,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,36,243,152,17,0,0,0,0,0,13,100,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,114,254,27,10,0,12,19,19,48,175,254,169,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,254,254,218,180,228,254,251,195,254,248,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,76,104,104,104,104,19,9,132,254,158,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,54,242,168,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,50,195,226,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,200,225,32,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,200,221,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,171,253,83,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,166,254,127,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,162,254,149,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,145,253,182,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,118,254,235,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,103,253,235,49,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,111,238,217,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,170,219,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,98,128,128,192,207,132,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,74,178,223,250,234,191,155,111,41,32,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,129,250,194,134,25,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,226,164,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,18,32,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,135,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,36,228,246,47,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,223,254,224,134,120,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,100,159,159,159,174,239,174,116,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,40,173,238,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,82,0,0,0,0,0,0,0,0,0,151,200,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,73,0,0,0,0,0,0,0,0,0,57,239,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,239,20,0,0,0,0,0,0,0,0,0,131,239,22,0,0,0,0,0,0,0,0,0,0,0,0,0,0,225,185,81,16,16,16,16,16,61,145,229,194,40,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,99,206,254,254,254,255,254,248,222,172,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,48,92,127,73,48,39,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,230,83,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,158,244,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,55,245,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,254,196,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,76,250,194,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,150,254,162,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,99,255,160,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,105,251,194,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,59,248,197,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,221,243,41,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,251,142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,190,245,102,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,63,254,155,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,223,254,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,230,175,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,185,242,56,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,241,110,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,129,235,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,201,231,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,170,171,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,67,146,216,255,254,255,255,139,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,68,237,253,205,177,177,177,239,253,208,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,200,253,50,12,0,0,0,26,196,253,137,114,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,253,253,21,0,0,0,0,0,135,253,253,248,63,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,222,253,21,0,0,0,0,0,170,253,253,106,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,107,253,72,0,0,1,37,207,252,218,45,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,49,253,199,18,18,113,253,253,169,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,171,253,146,147,253,253,183,32,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,188,253,253,245,140,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,92,246,253,253,55,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,124,253,253,253,253,55,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,141,253,253,128,62,240,236,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,195,253,242,111,7,0,138,239,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,47,234,253,203,39,0,0,0,93,249,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,221,253,233,28,0,0,0,0,53,247,132,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,253,242,48,0,0,0,0,0,93,248,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,251,79,0,0,0,0,0,0,136,232,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,248,0,0,0,7,33,40,210,241,156,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,252,160,106,179,193,253,253,208,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,147,253,253,202,145,145,93,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,129,253,192,109,109,109,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,115,252,252,253,252,252,252,156,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,63,216,252,252,253,252,252,252,253,66,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,108,108,170,128,211,252,253,252,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,252,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,125,253,210,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,47,221,253,252,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,145,144,221,252,253,210,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,171,253,253,253,255,253,253,253,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,253,252,252,252,253,252,220,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,215,215,215,253,252,215,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,148,236,144,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,218,253,170,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,93,252,210,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,120,104,0,0,0,0,0,0,0,0,94,252,190,0,0,0,0,0,0,0,0,0,0,0,0,0,42,160,252,143,0,0,0,0,0,0,0,0,217,231,46,0,0,0,0,0,0,0,0,0,0,0,0,0,218,253,253,191,15,0,0,0,0,0,0,47,233,217,0,0,0,0,0,0,0,0,0,0,0,0,0,0,175,252,252,252,222,217,217,135,175,94,217,233,252,91,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,175,215,252,252,252,252,253,252,252,252,253,179,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,108,108,108,190,108,232,252,168,108,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,121,213,255,255,121,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,52,108,157,241,251,253,253,242,146,69,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,94,164,241,253,253,223,159,131,26,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,60,102,218,253,253,216,117,39,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,54,205,253,253,253,147,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,60,240,253,253,253,243,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,80,208,253,253,147,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,36,222,253,253,121,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,177,242,253,248,147,148,91,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,120,197,253,254,253,97,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,192,254,254,40,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,242,253,39,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,253,159,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,253,173,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,253,173,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,253,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,0,0,0,0,0,0,0,0,0,20,201,253,39,0,0,0,0,0,0,0,0,0,0,0,0,0,0,196,161,41,5,0,0,0,3,27,98,206,253,194,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,115,240,252,163,147,147,147,158,253,253,255,184,67,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,157,253,253,253,253,253,253,253,121,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,192,230,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,152,252,193,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,129,252,190,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,155,252,210,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,62,216,199,66,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,43,254,222,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,143,252,222,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,169,246,208,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,143,246,236,101,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,69,226,199,111,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,254,253,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,124,253,110,5,0,0,0,0,0,22,128,191,190,137,28,0,0,0,0,0,0,0,0,0,0,0,0,112,241,170,32,0,0,0,31,127,180,237,252,253,252,242,42,0,0,0,0,0,0,0,0,0,0,0,6,190,226,0,0,0,0,27,218,252,194,162,84,84,131,232,35,0,0,0,0,0,0,0,0,0,0,0,110,252,147,0,0,0,0,194,253,217,56,0,0,18,216,187,0,0,0,0,0,0,0,0,0,0,0,0,233,216,18,0,0,0,27,194,150,106,9,0,124,255,186,9,0,0,0,0,0,0,0,0,0,0,0,64,247,110,0,0,0,0,0,0,0,0,87,146,163,63,16,0,0,0,0,0,0,0,0,0,0,0,0,14,236,128,0,0,0,11,22,66,128,206,231,178,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,239,196,169,82,169,211,252,252,128,84,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,36,241,252,252,253,217,138,42,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,48,48,22,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,62,97,198,243,254,254,212,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,67,172,254,254,225,218,218,237,248,40,0,21,164,187,0,0,0,0,0,0,0,0,0,0,0,0,0,89,219,254,97,67,14,0,0,92,231,122,23,203,236,59,0,0,0,0,0,0,0,0,0,0,0,0,25,217,242,92,4,0,0,0,0,4,147,253,240,232,92,0,0,0,0,0,0,0,0,0,0,0,0,0,101,255,92,0,0,0,0,0,0,105,254,254,177,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,167,244,41,0,0,0,7,76,199,238,239,94,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,192,121,0,0,2,63,180,254,233,126,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,190,196,14,2,97,254,252,146,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,130,225,71,180,232,181,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,130,254,254,230,46,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,77,244,254,162,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,110,254,218,254,116,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,131,254,154,28,213,86,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,209,153,19,19,233,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,142,254,165,0,14,216,167,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,90,254,175,0,18,229,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,229,249,176,222,244,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,73,193,197,134,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,29,125,147,255,255,241,51,0,0,0,0,0,0,0,0,0,0,0,0,0,0,49,12,104,118,118,222,248,249,253,253,253,253,253,231,0,0,0,0,0,0,0,0,0,0,0,0,0,0,229,243,252,253,253,253,253,253,253,253,253,253,253,176,0,0,0,0,0,0,0,0,0,0,0,0,0,0,181,253,253,253,253,253,253,253,178,167,253,253,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,25,139,112,25,25,25,25,7,46,253,253,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,93,253,253,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,176,253,253,244,69,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,240,253,253,227,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,156,253,253,253,190,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,201,253,253,245,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,90,253,253,253,124,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,202,253,253,245,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,253,245,109,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,205,253,253,207,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,253,253,207,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,202,253,253,253,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,206,253,253,249,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,253,253,253,194,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,253,253,253,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,227,253,223,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,191,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,0,64,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,255,255,255,255,255,255,255,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,255,255,255,191,0,191,255,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,255,128,255,255,255,255,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,255,255,255,255,255,128,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,0,128,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,64,0,64,191,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,128,0,0,0,64,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,0,0,0,0,0,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,64,0,0,0,0,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,191,128,191,128,191,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,255,255,255,255,255,255,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,255,255,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,191,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,89,156,231,255,163,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,165,253,253,253,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,43,153,224,253,253,180,174,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,70,237,253,207,71,19,2,0,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,147,253,253,177,23,0,0,0,0,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,217,254,254,131,0,0,0,0,0,83,255,254,101,0,0,0,0,0,0,0,0,0,0,0,0,0,87,229,254,251,135,3,0,0,0,44,132,244,254,253,129,0,0,0,0,0,0,0,0,0,0,0,0,85,247,253,235,124,0,0,0,0,112,229,253,253,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,175,253,253,120,0,0,52,212,235,250,253,253,253,254,167,6,0,0,0,0,0,0,0,0,0,0,0,16,235,253,253,240,195,195,248,253,254,253,253,253,253,231,24,0,0,0,0,0,0,0,0,0,0,0,0,20,254,254,254,255,254,254,222,120,38,5,156,254,254,38,0,0,0,0,0,0,0,0,0,0,0,0,0,3,136,233,241,241,225,135,25,0,0,103,253,253,207,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,30,30,0,0,0,0,19,196,253,240,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,112,253,253,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,231,253,222,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,158,255,254,152,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,199,254,236,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,70,253,254,135,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,227,253,207,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,159,253,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,110,109,109,47,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,176,217,253,252,252,232,218,93,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,37,182,201,252,252,253,252,252,252,253,252,92,0,0,0,0,0,0,0,0,0,0,0,0,0,1,42,160,252,253,252,252,252,253,252,252,252,253,252,215,1,0,0,0,0,0,0,0,0,0,0,0,63,170,252,252,252,253,252,252,252,253,252,252,252,253,252,252,108,0,0,0,0,0,0,0,0,0,0,73,237,252,252,252,252,253,252,252,252,253,231,179,221,253,252,252,232,0,0,0,0,0,0,0,0,0,53,232,252,252,252,252,252,253,252,252,252,237,71,0,125,253,252,252,252,0,0,0,0,0,0,0,0,0,73,252,252,252,252,252,252,253,252,252,252,62,0,0,0,253,252,252,168,0,0,0,0,0,0,0,0,0,42,222,253,253,253,253,253,255,222,125,0,0,0,0,63,255,253,237,62,0,0,0,0,0,0,0,0,0,21,201,252,252,252,252,252,253,55,0,0,0,0,0,144,253,252,215,0,0,0,0,0,0,0,0,0,0,73,252,252,252,252,252,252,253,190,72,0,0,0,6,160,253,252,195,0,0,0,0,0,0,0,0,0,0,155,252,252,252,252,252,252,253,252,236,62,0,0,120,252,253,210,31,0,0,0,0,0,0,0,0,0,171,253,253,253,253,159,41,0,0,0,0,0,110,150,253,253,255,119,0,0,0,0,0,0,0,0,0,0,253,252,252,252,252,35,0,0,0,0,11,73,253,252,252,252,222,25,0,0,0,0,0,0,0,0,0,0,253,252,252,252,252,190,181,181,99,181,191,252,253,252,252,231,41,0,0,0,0,0,0,0,0,0,0,0,253,252,252,252,252,252,252,252,253,252,252,252,253,252,231,46,0,0,0,0,0,0,0,0,0,0,0,0,192,253,253,253,253,253,253,253,255,253,253,253,255,119,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,180,252,252,252,252,252,252,253,252,200,179,35,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,71,71,71,195,195,71,72,71,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,255,109,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,199,253,253,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,229,253,247,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,141,253,253,94,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,192,253,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,192,253,253,43,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,233,253,253,43,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,87,253,253,253,43,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,186,253,253,196,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,235,253,253,172,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,56,253,253,253,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,153,253,253,195,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,239,253,253,179,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,153,253,253,253,136,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,203,253,253,253,55,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,153,253,253,253,144,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,203,253,253,253,61,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,253,253,253,226,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,253,253,253,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,109,253,137,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,191,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,255,255,255,255,255,255,255,128,128,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,191,128,0,0,0,64,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,128,0,0,0,0,0,0,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,128,0,0,0,0,0,0,0,64,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,191,128,128,128,128,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,128,128,128,128,191,255,255,128,0,0,0,0,0,0,0,0,0,0,0,255,255,255,255,255,255,128,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,118,242,218,96,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,98,178,254,254,254,251,220,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,163,220,254,254,254,254,254,254,254,150,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,240,254,254,254,254,254,254,254,254,249,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,246,254,254,237,160,130,229,254,254,254,130,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,183,222,103,50,0,0,77,254,254,250,53,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,207,254,254,251,68,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,254,254,254,252,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,212,254,254,254,254,244,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,77,185,230,254,254,254,239,45,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,60,207,254,254,254,81,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,254,254,254,199,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,254,254,254,254,75,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,254,254,254,254,75,0,0,0,0,0,0,0,0,0,0,0,0,0,80,90,0,0,0,0,0,0,0,7,254,254,254,254,75,0,0,0,0,0,0,0,0,0,0,0,0,186,247,250,134,0,0,0,0,0,70,222,254,254,254,155,10,0,0,0,0,0,0,0,0,0,0,0,0,214,254,254,252,129,63,63,101,200,236,254,254,254,234,41,0,0,0,0,0,0,0,0,0,0,0,0,0,64,211,254,254,254,254,254,254,254,254,254,254,238,69,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,73,192,254,254,254,254,254,254,254,254,234,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,117,187,254,254,254,254,164,114,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,217,228,35,0,0,0,0,113,241,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,116,254,218,32,0,0,0,54,238,254,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,254,254,74,0,0,0,46,236,254,198,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,216,254,250,67,0,0,0,154,254,254,142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,168,254,254,189,0,0,0,62,236,254,254,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,254,254,248,69,0,0,11,208,254,254,176,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,47,254,254,211,0,0,11,101,254,254,254,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,149,254,254,241,174,174,194,254,254,254,254,80,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,123,254,254,254,254,254,254,254,254,254,254,254,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,230,254,254,254,254,254,254,254,254,254,254,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,80,186,199,254,254,254,254,199,186,80,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,50,254,254,254,196,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,176,254,254,254,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,254,254,254,197,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,182,254,254,254,80,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,254,254,254,199,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,150,254,254,254,140,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,162,254,254,230,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,162,254,254,140,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,102,255,230,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,10,78,0,0,0,0,0,0,0,15,104,104,104,69,0,0,0,0,0,0,0,0,0,0,0,0,123,238,254,235,159,76,111,76,115,169,169,238,254,254,254,254,0,0,0,0,0,0,0,0,0,0,0,71,252,254,254,254,254,254,254,254,254,254,254,254,254,254,248,102,0,0,0,0,0,0,0,0,0,0,0,83,254,254,254,254,254,247,236,221,179,235,182,140,110,47,42,0,0,0,0,0,0,0,0,0,0,0,39,229,254,254,194,169,124,47,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,254,254,254,248,133,51,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,213,254,254,254,254,249,91,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,152,201,254,254,254,135,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,237,106,0,0,0,32,200,254,255,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,123,251,181,0,0,0,13,156,254,254,126,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,254,254,56,0,0,0,85,254,254,254,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,198,254,149,54,0,0,60,251,254,254,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,248,254,220,107,148,236,253,248,171,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,249,254,254,254,254,249,173,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,97,194,254,254,254,134,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,97,103,37,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,117,254,220,89,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,95,212,253,253,253,157,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,95,209,253,253,253,245,125,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,40,96,206,253,254,253,253,198,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,182,240,253,253,253,254,253,198,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,60,60,168,253,253,254,200,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,70,247,253,253,245,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,75,207,253,253,207,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,219,253,253,253,138,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,105,250,253,253,253,34,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,95,254,254,254,254,94,0,0,0,0,0,3,13,13,13,8,0,0,0,0,0,0,0,0,0,0,0,0,107,253,253,253,204,15,0,0,0,0,21,166,253,253,253,212,25,0,0,0,0,0,0,0,0,0,0,33,217,253,253,132,64,0,0,18,43,157,171,253,253,253,253,253,160,2,0,0,0,0,0,0,0,0,3,166,253,253,242,49,17,49,158,210,254,253,253,253,253,253,253,253,253,11,0,0,0,0,0,0,0,0,10,227,253,253,207,15,172,253,253,253,254,247,201,253,210,210,253,253,175,4,0,0,0,0,0,0,0,0,10,228,253,253,224,87,242,253,253,184,60,54,9,60,35,182,253,253,52,0,0,0,0,0,0,0,0,0,13,253,253,253,253,231,253,253,253,93,86,86,86,109,217,253,253,134,5,0,0,0,0,0,0,0,0,0,2,115,253,253,253,253,253,253,253,253,254,253,253,253,253,253,134,5,0,0,0,0,0,0,0,0,0,0,0,3,166,253,253,253,253,253,253,253,254,253,253,253,175,52,5,0,0,0,0,0,0,0,0,0,0,0,0,0,7,35,132,225,253,253,253,195,132,132,132,110,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGbpsb811xRu"
      },
      "source": [
        "**NOTE:** Executing the below cell might take some time (1-2 min) as the original MNIST dataset is large."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47d30efd-945e-4302-a9c2-670178356231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42fca7b-bbe7-41f9-fc3b-9ce7da401f08"
      },
      "source": [
        "file_name = \"mnist_train.csv\"\n",
        "data = np.genfromtxt(file_name, delimiter=',', dtype=np.int)\n",
        "print(f\"Shape of the data in {file_name} is: {data.shape} \\n\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the data in mnist_train.csv is: (60000, 785) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dcc216c-2afc-49fd-aad0-a6f78e995a6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af2cfd6-1a64-42d4-dc6e-89b6ba875486"
      },
      "source": [
        "MNIST_Y = data[:, 0].reshape(-1, 1)\n",
        "MNIST_X = data[:, 1:]\n",
        "\n",
        "print(f\"Shape of X: {MNIST_X.shape} \\n\")\n",
        "print(f\"Shape of Y: {MNIST_Y.shape} \\n\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X: (60000, 784) \n",
            "\n",
            "Shape of Y: (60000, 1) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffe9411d-c223-4146-942d-769db0f799c7"
      },
      "source": [
        "### 1. Ln Norm Distances between two Arrays\n",
        "\n",
        "Implement the **`Ln_norm_distances()`** function which computes the distance between a testing instance and each of the training instances.\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data\n",
        "  * A 2D numpy array of floats where each row represents the input of a training instance\n",
        "\n",
        "* **`test_x`** : Testing Input\n",
        "  * A 1D numpy array of floats \n",
        "\n",
        "* **`n`** \n",
        "  * `n` in the Ln-Norm Distance (>= 1)\n",
        "\n",
        "**Returns**: \n",
        "* Array of distances between testing instance and each of the training instances.\n",
        "  * A 1D numpy array of floats\n",
        "\n",
        "**HINT**: \n",
        "* You can make use of **`np.abs`**, **`np.sum`** and **`np.power`** methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TPG7nl5QskM"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2775424-f465-4072-974a-ed9465f0e42f"
      },
      "source": [
        "def Ln_norm_distances(train_X, test_x, n):\n",
        "    # ADD YOUR CODE HERE\n",
        "    abs_diff=np.abs(train_X-test_x)\n",
        "    #return abs_diff\n",
        "    distance=np.power(np.sum(abs_diff**n,axis=1),1/n)\n",
        "    return distance"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a9c90c8-94c8-46b0-bbf2-79535cc4ca41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c9cb82-1eca-4ec4-c77d-66f1bc36424f"
      },
      "source": [
        "#SAMPLE TEST CASE - 1\n",
        "train_X = np.array([[6.4, 53.2, 13.6, 0.0],\n",
        "                   [8, 3.2, -13.6, 5.0],\n",
        "                   [4, 5.2, 3.6, -9.0]])\n",
        "test_x = np.array([1.1, 26.2, 3.4, 15.5])\n",
        "n = 3\n",
        "distances = Ln_norm_distances(train_X, test_x, n)\n",
        "print(np.round(distances,4))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[29.0901 26.4793 28.8416]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74a02e92-6b1b-4fdc-95f1-107d39e6a089"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[29.0901 26.4793 28.8416]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1532d91f-54cd-43e4-97fd-b6653d99dee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bac7f12-0823-4fcb-9f3a-6593b561ec10"
      },
      "source": [
        "#SAMPLE TEST CASE - 2\n",
        "train_X = MNIST_X[307:407]\n",
        "test_x = MNIST_X[789]\n",
        "n = 3\n",
        "distances = Ln_norm_distances(train_X, test_x, n)\n",
        "print(np.round(distances,4))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1129.4165 1262.3648 1063.4474 1075.0119 1156.043  1168.7321 1164.6504\n",
            " 1231.9049 1053.9743 1157.1013 1207.4119 1157.4291 1106.2678 1146.9765\n",
            "  796.5887 1195.7953 1261.094  1175.9254 1255.1906 1130.1494  829.6661\n",
            " 1083.695  1179.6641  969.9507 1148.3287 1132.9348 1170.6434 1186.3345\n",
            " 1037.713  1102.7552 1188.6005 1137.8926 1237.1169 1089.209  1002.8673\n",
            " 1030.239  1095.3997 1209.9582 1068.6931  940.467  1180.7639 1053.012\n",
            " 1174.4854 1177.8004 1084.5534 1118.6905 1124.7611 1124.6212 1089.5625\n",
            " 1073.6407 1064.9932 1112.8058 1168.6047 1244.4475 1047.1739 1150.7661\n",
            " 1124.734  1130.0033 1191.8754 1066.6603 1205.6465 1066.979  1144.8678\n",
            " 1124.1632 1166.4694 1128.5795 1158.3456 1188.719  1257.1978 1124.327\n",
            " 1135.4052 1177.05   1117.3271 1309.717  1150.0556 1155.1171 1140.4081\n",
            " 1085.5763 1313.9594 1222.9404 1138.5582 1084.7242 1101.1324 1059.8499\n",
            " 1134.1731 1189.8706 1179.9734 1143.1622 1172.6661 1013.8943 1067.2264\n",
            " 1074.593  1160.0227 1171.8602 1082.447  1144.4525  999.1315 1053.9368\n",
            "  998.6862 1132.6287]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa93731b-d400-4ce3-b8c5-25a58e52fce6"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[1129.4165 1262.3648 1063.4474 1075.0119 1156.043  1168.7321 1164.6504\n",
        " 1231.9049 1053.9743 1157.1013 1207.4119 1157.4291 1106.2678 1146.9765\n",
        "  796.5887 1195.7953 1261.094  1175.9254 1255.1906 1130.1494  829.6661\n",
        " 1083.695  1179.6641  969.9507 1148.3287 1132.9348 1170.6434 1186.3345\n",
        " 1037.713  1102.7552 1188.6005 1137.8926 1237.1169 1089.209  1002.8673\n",
        " 1030.239  1095.3997 1209.9582 1068.6931  940.467  1180.7639 1053.012\n",
        " 1174.4854 1177.8004 1084.5534 1118.6905 1124.7611 1124.6212 1089.5625\n",
        " 1073.6407 1064.9932 1112.8058 1168.6047 1244.4475 1047.1739 1150.7661\n",
        " 1124.734  1130.0033 1191.8754 1066.6603 1205.6465 1066.979  1144.8678\n",
        " 1124.1632 1166.4694 1128.5795 1158.3456 1188.719  1257.1978 1124.327\n",
        " 1135.4052 1177.05   1117.3271 1309.717  1150.0556 1155.1171 1140.4081\n",
        " 1085.5763 1313.9594 1222.9404 1138.5582 1084.7242 1101.1324 1059.8499\n",
        " 1134.1731 1189.8706 1179.9734 1143.1622 1172.6661 1013.8943 1067.2264\n",
        " 1074.593  1160.0227 1171.8602 1082.447  1144.4525  999.1315 1053.9368\n",
        "  998.6862 1132.6287]\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c7133b7-fea1-44dc-abcb-1e8df98454f7"
      },
      "source": [
        "### 2. k-nearest Neighbours\n",
        "\n",
        "Implement the `k_nearest_neighbours()` function which computes the k nearest neighbours of a testing instance.\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data\n",
        "  * A 2D numpy array of floats where each row represents the input of a training instance\n",
        "\n",
        "* **`test_x`** : Testing Input\n",
        "  * A 1D numpy array of floats\n",
        "\n",
        "* **`n`** \n",
        "  * `n` in Ln-Norm Distance (>=1)\n",
        "\n",
        "* **`k`** \n",
        "  * The number of nearest neighbours to consider. \n",
        "  * 1 $\\le$ **k** $\\le$ number of training instances\n",
        "\n",
        "**Returns**:\n",
        "* Indices of k-nearest neighbours to **`test_x`**.\n",
        " * A 1D numpy array of `ints`\n",
        "* Distances of the corresponding k-nearest neighbors from **`test_x`**.\n",
        " * A 1D numpy array of `floats`\n",
        "\n",
        "**NOTE:**   \n",
        "In case of a distance tie, break the tie by considering all the points equidistant from **`test_x`**. That is, return all the points which are equidistant from **`test_x`**.\n",
        "\n",
        "\n",
        "**HINT**: \n",
        "* You can call **`Ln_norm_distances`** method implemented in the previous question.\n",
        "* You can make use of **`np.argsort`** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "724bbc19-54e5-44f6-93f6-3d32d396dc56"
      },
      "source": [
        "def k_nearest_neighbours(train_X, test_x, n, k):\n",
        "  # ADD YOUR CODE HERE\n",
        "  distances=Ln_norm_distances(train_X,test_x,n)    \n",
        "  indices=np.argsort(distances)\n",
        "  k_nearest=distances[indices]\n",
        "  k_actual=[]\n",
        "  count=0\n",
        "\n",
        "  for i in range(len(k_nearest)):\n",
        "    if i!=(len(k_nearest)-1):       \n",
        "      if k_nearest[i]==k_nearest[i+1]:\n",
        "        k_actual.append(k_nearest[i])\n",
        "        count+=0\n",
        "      elif k_nearest[i]!=k_nearest[i+1]:\n",
        "        k_actual.append(k_nearest[i])\n",
        "        count+=1      \n",
        "      if count==k:\n",
        "        break\n",
        "    if i==(len(k_nearest)-1):\n",
        "      if k_nearest[i]==k_nearest[i-1]:\n",
        "        k_actual.append(k_nearest[i])\n",
        "      elif k_nearest[i]!=k_nearest[i-1]:\n",
        "        k_actual.append(k_nearest[i])\n",
        "\n",
        "  \n",
        "  k_actual=np.array(k_actual)       \n",
        "\n",
        "      \n",
        "  return indices[:len(k_actual)],k_actual\n",
        "\n",
        "  \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "999970ff-1911-4d33-b234-2f99f576a2c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d6f644-00b5-4e07-e02d-c67c3fcc7d06"
      },
      "source": [
        "#SAMPLE TEST CASE - 1\n",
        "\n",
        "train_X = np.array([[3.4 ,7.2 ,-9.4, 5.2 ,7.43],\n",
        "       [18.5, -0.23, 45.2 ,6.3 ,-7.4],\n",
        "       [101.4 ,56.31 ,46.2, -6.5 ,-0.34],\n",
        "       [101.4 ,56.31 ,46.2, -6.5 ,-0.34],\n",
        "       [21.3, -7.45 ,8.91, 4.52, 81.23]\n",
        "       ])\n",
        "test_x = np.array([21.1 ,5.6 ,14.32 ,-6.73, -9.37])\n",
        "n = 4\n",
        "k = 3\n",
        "top_indices, top_distances = k_nearest_neighbours(train_X, test_x, n, k)\n",
        "print(top_indices)\n",
        "print(np.round(top_distances,4))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3]\n",
            "[26.784 31.132 83.764 83.764]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a84a3d4-b58d-4ea4-bbff-b06b3fba9a9a"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[0 1 2 3]\n",
        "[26.784 31.132 83.764 83.764]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a359b44e-24cc-4442-ada1-9d086b7f33ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ce9a06-6469-4e6c-b393-90ce48c17b17"
      },
      "source": [
        "#SAMPLE TEST CASE - 2\n",
        "\n",
        "train_X = MNIST_X[307:407]\n",
        "test_x = MNIST_X[789]\n",
        "n = 3\n",
        "k = 6\n",
        "top_indices, top_distances = k_nearest_neighbours(train_X, test_x, n, k)\n",
        "print(top_indices)\n",
        "print(np.round(top_distances,4))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[14 20 39 23 98 96]\n",
            "[796.5887 829.6661 940.467  969.9507 998.6862 999.1315]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3e293a7-de38-4f12-a93c-f6a1b68ed65d"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[14 20 39 23 98 96]\n",
        "[796.5887 829.6661 940.467  969.9507 998.6862 999.1315]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de526afc-6b0e-436a-8f1e-bda7d63b6379"
      },
      "source": [
        "### 3. Distance weighted k-NN\n",
        "Implement the `distance_weighted_knn()` function which predicts the class label for testing instances based on the *'Distance Weighted k-NN'* algorithm discussed in the sessions.\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data.\n",
        "  * A 2D numpy array of `floats` where each row represents the input of a training instance\n",
        "\n",
        "* **`train_Y`** : Outputs from training data (target labels).\n",
        "  * A 1D numpy array of `ints`\n",
        "\n",
        "* **`test_X`** : Inputs from testing data for which the class labels have to be predicted.\n",
        "  * A 2D numpy array of `floats` where each row represents the input of a testing instance\n",
        "\n",
        "\n",
        "* **`n`** \n",
        "  * `n` in Ln-Norm Distance (>=1)\n",
        "\n",
        "* **`k`** \n",
        "  * The number of nearest neighbours to consider.\n",
        "  * 1 $\\le$ **k** $\\le$ number of training instances.\n",
        "\n",
        "**Returns**:\n",
        "* Predicted labels for `test_X` \n",
        " * A 1D numpy array of ints where $i^{th}$ element is the predicted label for $i^{th}$ element in **`test_X`**\n",
        "\n",
        "**NOTE:**  \n",
        "In case of a tie among the weighted votes, break the tie randomly. That is, choose one of the labels which are tied.\n",
        "\n",
        "**HINT**: \n",
        "* You can call **`k_nearest_neighbours`** method implemented in the previous question.\n",
        "* You can use the **`distance_weighted_voting`** method from the previous assignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2742fa27-1d1d-4f9f-a6b3-ef4873b84d64"
      },
      "source": [
        "def distance_weighted_knn(train_X, train_Y, test_X, n, k):\n",
        "    # ADD YOUR CODE HERE\n",
        "    predicted_labels=[]\n",
        "    for i in test_X:\n",
        "      #distances=Ln_norm_distances(train_X,i,n)\n",
        "      top_indices, top_distances = k_nearest_neighbours(train_X, i, n, k)\n",
        "      #print(top_indices)\n",
        "      #print(top_distances)\n",
        "      top_Y_labels=train_Y[top_indices]\n",
        "      top_Y_labels_unique=np.unique(top_Y_labels)\n",
        "      unique_labels_distance_dict=dict()\n",
        "      for j in top_Y_labels_unique:\n",
        "        indices_of_labels=np.where(top_Y_labels==j)\n",
        "        #print(indices_of_labels)\n",
        "        weighted_distance=0\n",
        "        indices_of_labels\n",
        "        for l in indices_of_labels:\n",
        "          #print(l)\n",
        "          weighted_distance+=1/top_distances[l]\n",
        "          #print(weighted_distance,l)\n",
        "        unique_labels_distance_dict[j]=sum(weighted_distance)\n",
        "      max_key=max(unique_labels_distance_dict,key=unique_labels_distance_dict.get)\n",
        "      predicted_labels.append(max_key)\n",
        "    predicted_labels_array=np.array(predicted_labels)\n",
        "    return predicted_labels_array\n",
        "\n",
        "\n",
        "           \n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8be4020f-ebd5-4ae5-a224-cf4671645784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693d3215-d7c4-486f-b676-68be020e92dc"
      },
      "source": [
        "#SAMPLE TEST CASE - 1\n",
        "\n",
        "train_X = np.array([[3.4, 89, -19.4, 5.2, 7.43],\n",
        "                    [8.5, -0.6, 45.2, 8.3, -78.4],\n",
        "                    [10.4, 6.33, 46.2, -6.5, -0.34],\n",
        "                    [0.5, 41, 66, 2.8, 56.2],\n",
        "                    [6.3, -7.45, 8.91, 4.56, 81.23]])\n",
        "test_X = np.array([[21.1, 5.6, 7.32, -6.73, -9.37], [0, 3.42, 51.63, 54.2, -7.3]])\n",
        "train_Y= np.array([1, 2, 2, 3, 1 ])\n",
        "n = 2\n",
        "k = 5\n",
        "predicted_test_Y = distance_weighted_knn(train_X, train_Y, test_X, n, k)\n",
        "print(predicted_test_Y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3164d21f-fc77-4682-bd63-9961ed7ea84c"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[2 2]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efbf3f91-671a-4e86-b552-13a1f187d237",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c721dc01-7606-4583-bf12-da4154395e94"
      },
      "source": [
        "#SAMPLE TEST CASE - 2\n",
        "\n",
        "train_X = MNIST_X[0:100]\n",
        "test_X = MNIST_X[100:120]\n",
        "train_Y = MNIST_Y[0:100].reshape(100,)\n",
        "\n",
        "n = 2\n",
        "k = 2\n",
        "predicted_test_Y = distance_weighted_knn(train_X,train_Y, test_X, n, k)\n",
        "print(predicted_test_Y)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 7 1 7 1 1 6 3 0 1 4 3 1 1 0 4 9 2 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7d10056-2cba-4acc-a8fb-6db371892032"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[9 7 1 7 1 1 6 3 0 1 4 3 1 1 0 4 9 2 0 0]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad862aad-691b-435e-81ee-bbfa61ce340a"
      },
      "source": [
        "### 4. Majority based k-NN\n",
        "Implement the `majority_based_knn()` function which predicts the class label for testing instances based on the majority label among k-nearest neighbors.\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data.\n",
        "  * A 2D numpy array of floats where each row represents the input of a training instance\n",
        "\n",
        "* **`train_Y`** : Outputs from training data (target labels).\n",
        "  * A 1D numpy array of ints\n",
        "\n",
        "* **`test_X`** : Inputs from testing data for which the class labels have to be predicted.\n",
        "  * A 2D numpy array of floats where each row represents the input of a testing instance\n",
        "\n",
        "* **`n`** \n",
        "  * `n` in Ln-Norm Distance (>=1)\n",
        "\n",
        "* **`k`** \n",
        "  * The number of nearest neighbours to consider.\n",
        "  * 1 $\\le$ **k** $\\le$ number of training instances.\n",
        "\n",
        "**Returns**:\n",
        "* Predicted labels for `test_X` \n",
        " * A 1D numpy array of ints where $i^{th}$ element is the predicted label for $i^{th}$ element in **`test_X`**\n",
        "\n",
        "**NOTE:**  \n",
        "* In case of voting ties, break the ties using the distance weighted voting technique discussed in the session.   \n",
        "* In case there is a tie even after considering weights, break it randomly.\n",
        "\n",
        "**HINT**: \n",
        "* You can make use of **`np.unique`**, **`np.argsort`**, **`np.max`**, **`np.where`** methods.\n",
        "* You can call **`k_nearest_neighbours`** method implemented in one of the previous questions.\n",
        "* You can use the **`distance_weighted_voting`** method from the previous assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50b2e6e6-800b-4242-8852-057d0e055969"
      },
      "source": [
        "def majority_based_knn(train_X, train_Y, test_X, n, k):    \n",
        "    # ADD YOUR CODE HERE\n",
        "    predicted_labels=[]\n",
        "    for i in test_X:\n",
        "      #distances=Ln_norm_distances(train_X,i,n)\n",
        "      top_indices, top_distances = k_nearest_neighbours(train_X, i, n, k)\n",
        "      top_Y_labels=train_Y[top_indices]\n",
        "      top_Y_labels_unique=np.unique(top_Y_labels)\n",
        "      unique_labels_distance_dict=dict()\n",
        "      majority_labels_dict=dict()\n",
        "      for j in top_Y_labels_unique:\n",
        "        count=np.count_nonzero(top_Y_labels==j)\n",
        "        majority_labels_dict[j]=count\n",
        "      max_key=max(majority_labels_dict,key=majority_labels_dict.get)\n",
        "      majority_labels_list=[]\n",
        "      for key,value in majority_labels_dict.items():\n",
        "        if value==majority_labels_dict[max_key]:\n",
        "          majority_labels_list.append(key)\n",
        "      if len(majority_labels_list)==1:\n",
        "        predicted_labels.append(majority_labels_list[0])\n",
        "      elif len(majority_labels_list)>1:\n",
        "        top_Y_labels_unique=np.array(majority_labels_list)\n",
        "        for j in top_Y_labels_unique:         \n",
        "          indices_of_labels=np.where(top_Y_labels==j)        \n",
        "          weighted_distance=0\n",
        "          for l in indices_of_labels:\n",
        "            weighted_distance+=1/top_distances[l]\n",
        "          unique_labels_distance_dict[j]=sum(weighted_distance)\n",
        "        max_key=max(unique_labels_distance_dict,key=unique_labels_distance_dict.get)\n",
        "        predicted_labels.append(max_key)\n",
        "    predicted_labels_array=np.array(predicted_labels)\n",
        "    return predicted_labels_array       "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48413340-43c8-4f8d-9c3e-867ee7dd3bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1133d321-9ac8-4bb3-a4dd-79d7dbc4a31a"
      },
      "source": [
        "#SAMPLE TEST CASE - 1\n",
        "\n",
        "train_X = np.array([[3.4, 89, -19.4, 5.2, 7.43],\n",
        "                    [8.5, -0.6, 45.2, 8.3, -78.4],\n",
        "                    [10.4, 6.33, 46.2, -6.5, -0.34],\n",
        "                    [0.5, 41, 66, 2.8, 56.2],\n",
        "                    [6.3, -7.45, 8.91, 4.56, 81.23]])\n",
        "test_X = np.array([[21.1, 5.6, 7.32, -6.73, -9.37], [0, 3.42, 51.63, 54.2, -7.3]])\n",
        "train_Y= np.array([1, 2, 2, 3, 1 ])\n",
        "n = 2\n",
        "k = 5\n",
        "predicted_test_Y = majority_based_knn(train_X, train_Y, test_X, n, k)\n",
        "print(predicted_test_Y)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feba88d8-f6f9-459e-89a0-a69dd82b2b3a"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[2 2]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c218d3f2-d17c-460e-a865-10d9f3580824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b25a3473-6350-44da-96df-ab8bdc3c8fbe"
      },
      "source": [
        "#SAMPLE TEST CASE - 2\n",
        "\n",
        "train_X = MNIST_X[0:100]\n",
        "test_X = MNIST_X[100:120]\n",
        "train_Y= MNIST_Y[0:100].flatten()\n",
        "\n",
        "n = 2\n",
        "k = 2\n",
        "predicted_test_Y = majority_based_knn(train_X,train_Y, test_X, n, k)\n",
        "print(predicted_test_Y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 7 1 7 1 1 6 3 0 1 4 3 1 1 0 4 9 2 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e6ac8e4-2ba3-4a84-9572-695b7be7c7a7"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[9 7 1 7 1 1 6 3 0 1 4 3 1 1 0 4 9 2 0 0]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69a37da6-f5fc-4b3f-8b72-4fe3b3d572c9"
      },
      "source": [
        "### 5. Accuracy of k-NN algorithm\n",
        "\n",
        "\n",
        "Implement the **`calculate_accuracy()`** function which computes the accuracy, given the actual and the predicted labels.\n",
        "\n",
        "**Arguments**:\n",
        "* **`predicted_labels`** \n",
        "  * A 1D numpy array of ints\n",
        "\n",
        "* **`actual_labels`** \n",
        "  * A 1D numpy array of ints\n",
        "\n",
        "**Returns**:\n",
        "* A `float` value which represents the accuracy for given **`predicted_labels`** and **`actual_labels`**\n",
        "\n",
        "**HINT**: \n",
        "* You can make use of **`np.count_nonzero`** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b65d04ea-00b8-472a-a17c-ccf7e5d7c5bd"
      },
      "source": [
        "def calculate_accuracy(predicted_labels, actual_labels):\n",
        "    # ADD YOUR CODE HERE\n",
        "    return (np.count_nonzero(predicted_labels==actual_labels)/len(predicted_labels))\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "256c0243-7c18-432a-933d-0a20c5bc2a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33317524-1201-45fc-98ce-271132429044"
      },
      "source": [
        "#SAMPLE TEST CASE - 1\n",
        "predicted_labels = np.array([1, 2, 3, 4, 5])\n",
        "actual_labels= np.array([1, 2, 2, 4, 5])\n",
        "accuracy = calculate_accuracy(predicted_labels, actual_labels)\n",
        "print(np.round(accuracy,4))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20918410-9837-4a57-9711-7c25dac86e2d"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "0.8\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99892a36-a285-4b6d-b80a-2bc551f51e48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee848b1-d432-47e5-97b8-6c6c4fda98dc"
      },
      "source": [
        "#SAMPLE TEST CASE - 2\n",
        "\n",
        "predicted_labels = MNIST_Y[0:100].flatten()\n",
        "actual_labels = np.concatenate((MNIST_Y[0:70].flatten(), MNIST_Y[100:130].flatten()))\n",
        "accuracy = calculate_accuracy(predicted_labels, actual_labels)\n",
        "print(np.round(accuracy,4))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxDkqjBUJ1da"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "0.74\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_X9dHdIDX6T"
      },
      "source": [
        "\n",
        "### 6. Best `k` and `n` values [Optional]\n",
        "\n",
        "Implement the **`get_best_k_n_values_using_validation_set()`** function, which returns\n",
        "\n",
        "1.   the best **`'k'`** value, i.e., the number of nearest neighbors to consider and \n",
        "\n",
        "2.   the best **`'n'`** value in Ln-norm distance, i.e, the distance metric which should be used.\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data.\n",
        "  * A 2D numpy array of floats where each row represents the input of a training instance\n",
        "\n",
        "* **`train_Y`** : Outputs from training data (target labels).\n",
        "  * A 1D numpy array of `ints`\n",
        "\n",
        "* **`validation_split_percent`** : An `int` which denotes the percentage of `train_X` data that should be used as validation data.\n",
        "\n",
        "* **`possible_values_for_n`**\n",
        "  * An `ndarray` of `ints` which represents the values for **`n`** which should be considered when trying to find out the best value of `n` in Ln-norm distances.\n",
        "\n",
        "**Returns**:\n",
        "* The best **`k, n`** pair which should be used in the k-NN algorithm for the given data.\n",
        "  * A 1D numpy array of `ints` where the $1^{st}$ element is the **`k`** value and the second element is the **`n`** value.\n",
        "\n",
        "**NOTE:**  \n",
        "1. Shuffle the given training data before splitting it into training set and validation set.  \n",
        "2. From the shuffled training set,\n",
        "\n",
        "> 1. The first $math.floor(\\frac{100-P}{100}*M)$ number of instances should be used as the training set.  \n",
        "> 2. The remaining instances should be used as the validation set.  \n",
        "\n",
        "> Here, $P$ is the `validation_split_percent` and $M$ is the number of instances in `train_X`.\n",
        "\n",
        "3. Use the **`majority_based_knn()`** function that is implemented in the $4^{th}$ problem to predict labels using k-NN.\n",
        "4. For choosing the best value for $k$, try all possible values from 1 to number of instances in training set.<br>\n",
        "For the choosing best value for $n$, try values mentioned in the `possible_values_for_n` array. <br> <br>\n",
        "\n",
        "5. In case of a tie (same accuracies), return the **`(k, n)`** pair with the least value of **`'n'`**. If the **`'n'`** values of two or more such pairs are also the same, then return the **`(k, n)`** pair with the least value of **`'k'`** among such pairs. <br> <br>\n",
        "\n",
        "\n",
        "**HINT:**  \n",
        "* Use the hyperparameter tuning technique discussed in the sessions. That is, iteratively try various combinations of hyperparameter values and pick the values that give the best performance.  <br><br>\n",
        "\n",
        "* You can make use of **`np.argsort`** method.\n",
        "* You can call **`calculate_accuracy`** method implemented in the previous question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c394281-a995-4dc6-84b1-06119680a37f"
      },
      "source": [
        "import math\n",
        "def shuffle(X, Y):\n",
        "  np.random.seed(2) # DONT CHANGE THIS\n",
        "  # ADD CODE HERE TO SHUFFLE X, Y using numpy functions\n",
        "  data_count=X.shape[0]\n",
        "  permuted_indices=np.random.permutation(data_count)\n",
        "  return permuted_indices  \n",
        "\n",
        "\n",
        "def get_best_k_n_values_using_validation_set(train_X, train_Y, validation_split_percent,possible_values_for_n):    \n",
        "    # ADD YOUR CODE HERE\n",
        "    data_count=train_X.shape[0]\n",
        "    shuffled_data_indices=shuffle(train_X,train_Y)\n",
        "    shuffled_X=train_X[shuffled_data_indices]\n",
        "    shuffled_Y=train_Y[shuffled_data_indices]\n",
        "    train_count=math.floor(((100-validation_split_percent)/100)*data_count)\n",
        "    shuffled_train_X=shuffled_X[:train_count,:]\n",
        "    shuffled_train_Y=shuffled_Y[:train_count]\n",
        "    shuffled_validation_X=shuffled_X[train_count:,:]\n",
        "    shuffled_validation_Y=shuffled_Y[train_count:]\n",
        "    accuracy_max=0\n",
        "    for k in range(1,data_count+1):  \n",
        "      for n1 in n:\n",
        "        predicted_Y=majority_based_knn(shuffled_train_X, shuffled_train_Y, shuffled_validation_X, n1, k)\n",
        "        accuracy=calculate_accuracy(predicted_Y,shuffled_validation_Y)\n",
        "        if accuracy>accuracy_max:\n",
        "          best_values=np.array([k,n1])\n",
        "          accuracy_max=accuracy\n",
        "    return (best_values)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHt9r15SwBCV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba18168-9f3d-42bd-a4af-5808b0912ba3"
      },
      "source": [
        "#SAMPLE TEST CASE - 1\n",
        "\n",
        "train_X = np.array([[14.4, 14.3, -18.3], \n",
        "                    [11.43, -16.42, 3.78], \n",
        "                    [15.6, 12.3, 14.6]])\n",
        "train_Y= np.array([0, 0, 1])\n",
        "validation_split_percent = 20\n",
        "n = np.array([1,2,3,4])\n",
        "best_k_n = get_best_k_n_values_using_validation_set(train_X, train_Y, validation_split_percent, n)\n",
        "print(best_k_n)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tVZVWhGwWya"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[1 4]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "defb15bf-d1c7-4968-b65b-250803a4c434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847bd1e9-21e3-4ca9-abb9-303f6d4bc498"
      },
      "source": [
        "#SAMPLE TEST CASE - 2\n",
        "\n",
        "train_X = MNIST_X[568:678]\n",
        "train_Y= MNIST_Y[568:678].reshape(110,)\n",
        "validation_split_percent = 30\n",
        "n = np.array([1,2,3])\n",
        "best_k_n = get_best_k_n_values_using_validation_set(train_X, train_Y, validation_split_percent, n)\n",
        "print(best_k_n)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH55aJaIROfq"
      },
      "source": [
        "\n",
        "**Expected Output**:\n",
        "```\n",
        "[1 2]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9AL0gCDtvKP"
      },
      "source": [
        "# In total "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXgonjj2He-7"
      },
      "source": [
        "import numpy as np\n",
        "def Ln_norm_distances(train_X, test_x, n):\n",
        "    # ADD YOUR CODE HERE\n",
        "    abs_diff=np.abs(train_X-test_x)\n",
        "    #return abs_diff\n",
        "    distance=np.power(np.sum(abs_diff**n,axis=1),1/n)\n",
        "    return distance\n",
        "def k_nearest_neighbours(train_X, test_x, n, k):\n",
        "  # ADD YOUR CODE HERE\n",
        "  distances=Ln_norm_distances(train_X,test_x,n)    \n",
        "  indices=np.argsort(distances)\n",
        "  k_nearest=distances[indices]\n",
        "  k_actual=[]\n",
        "  count=0\n",
        "\n",
        "  for i in range(len(k_nearest)):\n",
        "    if i!=(len(k_nearest)-1):       \n",
        "      if k_nearest[i]==k_nearest[i+1]:\n",
        "        k_actual.append(k_nearest[i])\n",
        "        count+=0\n",
        "      elif k_nearest[i]!=k_nearest[i+1]:\n",
        "        k_actual.append(k_nearest[i])\n",
        "        count+=1      \n",
        "      if count==k:\n",
        "        break\n",
        "    if i==(len(k_nearest)-1):\n",
        "      if k_nearest[i]==k_nearest[i-1]:\n",
        "        k_actual.append(k_nearest[i])\n",
        "      elif k_nearest[i]!=k_nearest[i-1]:\n",
        "        k_actual.append(k_nearest[i])\n",
        "\n",
        "  \n",
        "  k_actual=np.array(k_actual)       \n",
        "\n",
        "      \n",
        "  return indices[:len(k_actual)],k_actual\n",
        "\n",
        "  \n",
        "\n",
        "def distance_weighted_knn(train_X, train_Y, test_X, n, k):\n",
        "    # ADD YOUR CODE HERE\n",
        "    predicted_labels=[]\n",
        "    for i in test_X:\n",
        "      #distances=Ln_norm_distances(train_X,i,n)\n",
        "      top_indices, top_distances = k_nearest_neighbours(train_X, i, n, k)\n",
        "      top_Y_labels=train_Y[top_indices]\n",
        "      top_Y_labels_unique=np.unique(top_Y_labels)\n",
        "      unique_labels_distance_dict=dict()\n",
        "      for j in top_Y_labels_unique:\n",
        "        indices_of_labels=np.where(top_Y_labels==j)\n",
        "        weighted_distance=0\n",
        "        for l in indices_of_labels:\n",
        "          weighted_distance+=1/top_distances[l]\n",
        "        unique_labels_distance_dict[j]=sum(weighted_distance)\n",
        "      max_key=max(unique_labels_distance_dict,key=unique_labels_distance_dict.get)\n",
        "      predicted_labels.append(max_key)\n",
        "    predicted_labels_array=np.array(predicted_labels)\n",
        "    return predicted_labels_array\n",
        "           \n",
        "\n",
        "def majority_based_knn(train_X, train_Y, test_X, n, k):    \n",
        "    # ADD YOUR CODE HERE\n",
        "    predicted_labels=[]\n",
        "    for i in test_X:\n",
        "      #distances=Ln_norm_distances(train_X,i,n)\n",
        "      top_indices, top_distances = k_nearest_neighbours(train_X, i, n, k)\n",
        "      top_Y_labels=train_Y[top_indices]\n",
        "      top_Y_labels_unique=np.unique(top_Y_labels)\n",
        "      unique_labels_distance_dict=dict()\n",
        "      majority_labels_dict=dict()\n",
        "      for j in top_Y_labels_unique:\n",
        "        count=np.count_nonzero(top_Y_labels==j)\n",
        "        majority_labels_dict[j]=count\n",
        "      max_key=max(majority_labels_dict,key=majority_labels_dict.get)\n",
        "      majority_labels_list=[]\n",
        "      for key,value in majority_labels_dict.items():\n",
        "        if value==majority_labels_dict[max_key]:\n",
        "          majority_labels_list.append(key)\n",
        "      if len(majority_labels_list)==1:\n",
        "        predicted_labels.append(majority_labels_list[0])\n",
        "      elif len(majority_labels_list)>1:\n",
        "        top_Y_labels_unique=np.array(majority_labels_list)\n",
        "        for j in top_Y_labels_unique:         \n",
        "          indices_of_labels=np.where(top_Y_labels==j)        \n",
        "          weighted_distance=0\n",
        "          for l in indices_of_labels:\n",
        "            weighted_distance+=1/top_distances[l]\n",
        "          unique_labels_distance_dict[j]=sum(weighted_distance)\n",
        "        max_key=max(unique_labels_distance_dict,key=unique_labels_distance_dict.get)\n",
        "        predicted_labels.append(max_key)\n",
        "    predicted_labels_array=np.array(predicted_labels)\n",
        "    return predicted_labels_array       \n",
        "def calculate_accuracy(predicted_labels, actual_labels):\n",
        "    # ADD YOUR CODE HERE\n",
        "    return (np.count_nonzero(predicted_labels==actual_labels)/len(predicted_labels))\n",
        "\n",
        "\n",
        "\n",
        "import math\n",
        "def shuffle(X, Y):\n",
        "  np.random.seed(2) # DONT CHANGE THIS\n",
        "  # ADD CODE HERE TO SHUFFLE X, Y using numpy functions\n",
        "  data_count=X.shape[0]\n",
        "  permuted_indices=np.random.permutation(data_count)\n",
        "  return permuted_indices  \n",
        "\n",
        "\n",
        "def get_best_k_n_values_using_validation_set(train_X, train_Y, validation_split_percent,possible_values_for_n):    \n",
        "    # ADD YOUR CODE HERE\n",
        "    data_count=train_X.shape[0]\n",
        "    shuffled_data_indices=shuffle(train_X,train_Y)\n",
        "    shuffled_X=train_X[shuffled_data_indices]\n",
        "    shuffled_Y=train_Y[shuffled_data_indices]\n",
        "    train_count=math.floor(((100-validation_split_percent)/100)*data_count)\n",
        "    shuffled_train_X=shuffled_X[:train_count,:]\n",
        "    shuffled_train_Y=shuffled_Y[:train_count]\n",
        "    shuffled_validation_X=shuffled_X[train_count:,:]\n",
        "    shuffled_validation_Y=shuffled_Y[train_count:]\n",
        "    accuracy_max=0\n",
        "    for k in range(1,data_count+1):  \n",
        "      for n1 in n:\n",
        "        predicted_Y=majority_based_knn(shuffled_train_X, shuffled_train_Y, shuffled_validation_X, n1, k)\n",
        "        accuracy=calculate_accuracy(predicted_Y,shuffled_validation_Y)\n",
        "        if accuracy>accuracy_max:\n",
        "          best_values=np.array([k,n1])\n",
        "          accuracy_max=accuracy\n",
        "    return (best_values)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}